<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h1 id="the-hidden-costs-of-ai-development-what-ive-learned-working-across-global-tech-ecosystems">The Hidden Costs of AI Development: What I’ve Learned Working Across Global Tech Ecosystems</h1> <p><em>Posted on March 15, 2025 by Danial Amin</em></p> <p><strong>Abstract</strong>: Through my work as an AI Tech Lead across startups, enterprises, and government projects spanning Pakistan, the US, Ireland, and France, I’ve witnessed firsthand how the current AI development paradigm creates unequal relationships between technology-producing and technology-consuming regions. This isn’t an abstract critique—it’s based on real observations from the ground about data flows, labor practices, and whose voices shape AI development.</p> <hr> <p>Over the past seven years, I’ve had the privilege of working on AI projects across multiple continents—from aerospace applications in Pakistan to startup ecosystems in Ireland, from enterprise solutions in the Caribbean to design innovation in France. What I’ve observed isn’t the democratizing force that AI advocates often promise, but a more complex reality where the benefits and burdens of AI development are unevenly distributed.</p> <p>This post reflects on what I’ve learned about the global AI ecosystem and raises questions we need to address as the technology becomes more pervasive.</p> <h2 id="the-data-extraction-reality">The Data Extraction Reality</h2> <p>During my time leading data science teams at various organizations, I’ve seen how data flows in the global AI economy. When we built analytics frameworks for enterprise clients, the pattern was consistent: data generated in emerging markets often gets processed and monetized by platforms headquartered elsewhere<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>.</p> <p>Take mobile financial services, an area I’ve worked on extensively. While innovations like M-Pesa originated in Kenya<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>, the behavioral data generated by millions of users across Africa increasingly flows to Western AI companies building credit scoring and fraud detection systems. The insights derived from this data—understanding spending patterns, predicting financial behavior, optimizing user interfaces—become intellectual property that’s then licensed back to local financial institutions<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup>.</p> <p>This isn’t inherently problematic, but it raises questions about value distribution. When a startup in Silicon Valley uses transaction data from Lagos to improve their algorithm, who benefits from that improvement? Usually, it’s the shareholders of the Silicon Valley company, not the Lagos users whose behavior created the training data.</p> <h2 id="the-invisible-workforce">The Invisible Workforce</h2> <p>Through platforms like Omdena, where I led machine learning projects for social impact, I regularly worked with data scientists and ML engineers from across the Global South. The talent and dedication were extraordinary, but the economic dynamics were troubling.</p> <p>Many of the data annotation and model training tasks that make AI systems possible are outsourced to countries where labor costs are lower<sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">4</a></sup>. I’ve seen brilliant engineers in Pakistan, India, and the Philippines working on cutting-edge AI projects for a fraction of what their counterparts in Silicon Valley earn for similar work.</p> <p>Content moderation—the essential but traumatic work of training AI systems to recognize harmful content—is disproportionately performed by workers in Kenya, the Philippines, and other countries where Western tech companies can hire talent cheaply<sup id="fnref:5"><a href="#fn:5" class="footnote" rel="footnote" role="doc-noteref">5</a></sup>. These workers face significant psychological risks while protecting users in wealthier countries from disturbing content.</p> <h2 id="language-and-cultural-bias-in-practice">Language and Cultural Bias in Practice</h2> <p>While building LLM-based solutions like Bob-The Startup Advisor and Sandy-The Financial Advisor, I encountered the limitations of current AI models firsthand. Despite claims of multilingual capability, these systems struggle with non-English contexts in ways that go beyond simple translation.</p> <p>Large language models trained primarily on English text exhibit systematic biases when dealing with non-Western concepts<sup id="fnref:6"><a href="#fn:6" class="footnote" rel="footnote" role="doc-noteref">6</a></sup>. When I tested financial advisory models with questions about Islamic banking principles or traditional business practices common in South Asian markets, the responses were often inadequate or culturally inappropriate.</p> <p>This isn’t just a technical limitation—it reflects whose knowledge and perspectives are valued in AI training data. The vast majority of text used to train large language models comes from English-language sources, primarily from Western contexts<sup id="fnref:7"><a href="#fn:7" class="footnote" rel="footnote" role="doc-noteref">7</a></sup>. Local knowledge systems, indigenous practices, and non-Western ways of organizing information are systematically underrepresented.</p> <h2 id="the-innovation-periphery">The Innovation Periphery</h2> <p>One of the most frustrating aspects of the current AI ecosystem is how innovation is perceived and valued. During my MBA at Rennes School of Business, I studied how technological innovation is often framed as flowing from “centers” (Silicon Valley, Boston, London) to “peripheries” (everywhere else).</p> <p>This framing ignores the reality I’ve witnessed: incredible innovation happening across the Global South, often out of necessity rather than venture capital abundance. The aerospace projects I worked on in Pakistan involved sophisticated optimization algorithms developed under resource constraints that would be unimaginable in Western tech companies.</p> <p>Yet these innovations rarely receive global recognition or investment. The AI research emerging from universities in Nigeria, Pakistan, Brazil, or India is often overlooked by major conferences and journals, which maintain editorial boards dominated by Western institutions<sup id="fnref:8"><a href="#fn:8" class="footnote" rel="footnote" role="doc-noteref">8</a></sup>.</p> <h2 id="a-more-nuanced-path-forward">A More Nuanced Path Forward</h2> <p>I’m not arguing that all AI development should be localized or that global collaboration is inherently problematic. The projects I’ve worked on have benefited enormously from international collaboration and knowledge sharing.</p> <p>But we need more honest conversations about power dynamics in AI development. Some concrete steps that could help:</p> <ol> <li> <p><strong>Equitable Partnership Models</strong>: When AI companies use data from emerging markets, they should share the value created, not just extract insights<sup id="fnref:9"><a href="#fn:9" class="footnote" rel="footnote" role="doc-noteref">9</a></sup>.</p> </li> <li> <p><strong>Diverse Training Data</strong>: Deliberate efforts to include non-Western knowledge sources in AI training data, with proper compensation and attribution to source communities<sup id="fnref:10"><a href="#fn:10" class="footnote" rel="footnote" role="doc-noteref">10</a></sup>.</p> </li> <li> <p><strong>Local AI Capacity Building</strong>: Investment in AI research institutions and startups in the Global South, not just outsourcing implementation work<sup id="fnref:11"><a href="#fn:11" class="footnote" rel="footnote" role="doc-noteref">11</a></sup>.</p> </li> <li> <p><strong>Ethical Labor Practices</strong>: Fair compensation and psychological support for workers performing essential but difficult AI training tasks<sup id="fnref:12"><a href="#fn:12" class="footnote" rel="footnote" role="doc-noteref">12</a></sup>.</p> </li> </ol> <h2 id="questions-for-the-ai-community">Questions for the AI Community</h2> <p>As someone who has worked across this ecosystem, I’m left with questions that the AI community needs to address:</p> <ul> <li>How do we ensure that AI development serves local needs rather than just global markets?</li> <li>What does equitable participation in the AI economy actually look like?</li> <li>How can we preserve cultural diversity while benefiting from AI’s connective potential?</li> <li>Who should have control over AI systems that affect millions of people?</li> </ul> <p>These aren’t abstract philosophical questions—they’re practical challenges that will determine whether AI becomes a force for reducing or increasing global inequality.</p> <p>The technology itself is remarkable. I’ve seen AI systems optimize supply chains, predict equipment failures, and automate routine tasks in ways that genuinely improve people’s lives. But technology alone doesn’t determine outcomes—the economic and social structures around it do.</p> <p>As AI practitioners, we have a responsibility to think critically about these structures and work toward more equitable alternatives. The future of AI isn’t predetermined, but it won’t democratize itself.</p> <hr> <p><em>Danial Amin is an AI Tech Lead currently working on generative AI solutions for design optimization at Samsung Design Innovation Center in France. He has led AI projects across multiple continents and holds advanced degrees in both technical and business domains. You can connect with him on <a href="https://linkedin.com/in/danial-amin" rel="external nofollow noopener" target="_blank">LinkedIn</a> or view his technical work on <a href="https://github.com/danial-amin" rel="external nofollow noopener" target="_blank">GitHub</a>.</em></p> <hr> <h2 id="references">References</h2> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>Zuboff, S. (2019). <em>The Age of Surveillance Capitalism</em>. PublicAffairs. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:2"> <p>Hughes, N., &amp; Lonie, S. (2007). M-PESA: mobile money for the “unbanked” turning cellphones into 24-hour tellers in Kenya. <em>Innovations</em>, 2(1-2), 63-81. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:3"> <p>Aitken, R. (2017). ‘All data is credit data’: Constituting the unbanked. <em>Competition &amp; Change</em>, 21(4), 274-300. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:4"> <p>Gray, M. L., &amp; Suri, S. (2019). <em>Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass</em>. Houghton Mifflin Harcourt. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:5"> <p>Roberts, S. T. (2019). <em>Behind the Screen: Content Moderation in the Shadows of Social Media</em>. Yale University Press. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:6"> <p>Bender, E. M., et al. (2021). On the dangers of stochastic parrots: Can language models be too big? <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>, 610-623. <a href="#fnref:6" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:7"> <p>Rogers, A., et al. (2020). What’s in your embedding? Analyzing word embedding bias in conceptual spaces. <em>Proceedings of the 1st Workshop on Gender Bias in Natural Language Processing</em>, 1-16. <a href="#fnref:7" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:8"> <p>Mohamed, S., et al. (2020). Decolonising science–reconstructing relations. <em>eLife</em>, 9, e65546. <a href="#fnref:8" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:9"> <p>McDonald, S., &amp; Milne, R. (2021). Corporate power and global health governance: The example of foundation and pharmaceutical industry relations. <em>Global Social Policy</em>, 21(2), 275-297. <a href="#fnref:9" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:10"> <p>Blodgett, S. L., et al. (2020). Language (technology) is power: A critical survey of “bias” in NLP. <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, 5454-5476. <a href="#fnref:10" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:11"> <p>Adams, R. (2021). Can artificial intelligence be decolonized? <em>Interdisciplinary Science Reviews</em>, 46(1-2), 176-197. <a href="#fnref:11" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:12"> <p>Gillespie, T. (2018). <em>Custodians of the Internet: Platforms, Content Moderation, and the Hidden Decisions That Shape Social Media</em>. Yale University Press. <a href="#fnref:12" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </body></html>